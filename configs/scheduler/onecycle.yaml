# @package _global_
train:
  interval: step

scheduler:
  # _target_: torch.optim.lr_scheduler.OneCycleLR
  _name_: onecycle
  max_lr: 0.001
  epochs: ${trainer.max_epochs}
  steps_per_epoch: 1563
