# @package _global_
defaults:
  - /pipeline: cifar10
  - /model: resnet18
  # - override /scheduler: cosine_warmup_restarts
  - override /scheduler: cosine
  - override /optimizer: sgd

model:
  squeeze_excitation_rd_ratio: 0.1

#scheduler:
#  num_warmup_steps: 100
#  num_training_steps: 78125  # (50000 / 32) * 50 epochs = 1562.5 * 50 = 78,125
#  num_cycles: 3
scheduler:
  T_max: ${trainer.max_epochs}
  eta_min: 0

optimizer:
  lr: 0.1
  momentum: 0.9
  dampening: 0
  weight_decay: 0.0005
  nesterov: True

loader:
  batch_size: 128

trainer:
  max_epochs: 50
  watch_model: true  # [THIS IS MASSIVELY SLOWING TRAINING DOWN] Watch model parameters+gradients with wandb.
  track_grad_norm: 2 # [THIS IS MASSIVELY SLOWING TRAINING DOWN] Track L2 norms of gradients

train:
  seed: 2222