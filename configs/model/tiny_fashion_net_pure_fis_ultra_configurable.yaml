_target_: src.models.tiny_fashion_net.TinyFashionNetPureFISUltraConfigurable

# Layer configuration: [input_ch, (layer_type, params), out_ch, (layer_type, params), out_ch, ...]
# Layer types:
#   - ('fis', semiring): FIS layer with semiring ('maxplus', 'real', 'maxtimes')
#   - ('cnn', cnn_type): CNN layer ('channelwise' for 1x1, 'standard' for 3x3)
# Example: [8, ('fis', 'maxplus'), 16, ('cnn', 'channelwise'), 4, ('fis', 'real'), 4]
layer_config:
  - 1                    # Input channels
  - ['cnn', 'standard']  # CNN layer standard (kernel size 3)
  - 8                    # Input channels
  - ['fis', 'real']   # FIS layer with maxplus semiring
  - 16                   # Output channels
  - ['cnn', 'channelwise']  # CNN layer channelwise (kernel size 3)
  - 16                    # Output channels
  - ['fis', 'maxtimes']      # FIS layer with real semiring
  - 4                    # Final output channels

# Input channels for the first layer (default 1 for grayscale)
cnn_in_channels: 1

# Training parameters
p_drop: 0.0
num_classes: 10

# Skip connections
use_skip_connections: false
skip_connections_gamma: null  # None for no gamma, float for gamma init value

# FIS layer parameters
maxplus_linear: false
use_valuation: false
maxplus_normalization: false
use_discounted_sums: false
discount_init: 0.99
num_nodes: 2  # 2 or 3

# FIS layer seeds (null for default [0, 3, 0, 3, ...] pattern)
# Must have length equal to number of FIS layers in layer_config
fis_seeds: null

# Fix alpha_1 for FIS layers (null for all None)
# Must have length equal to number of FIS layers in layer_config
fix_alpha_1: null

# Internal activation for sums
sums_internal_activation: null  # None for no activation, 'zero' for debugging, 'relu' for standard activation, ...

# Pooling mode
pool_mode: max  # "max" or "avg"

# Positional encoding
use_positional_encoding: false
pe_type: sinusoidal_2d
pe_kwargs: null
pe_before_layer: null  # Which layer to apply PE before (None = before last)

# CNN layer parameters
cnn_kernel_size: 3  # Kernel size for standard CNN layers
cnn_use_relu: true  # Whether to use ReLU activation in CNN layers

# Complex mode parameters
use_complex: false
complex_use_only_real_part: false
complex_init_r_min: 0.1
complex_init_r_max: 0.99
complex_init_max_phase: 6.283185307179586